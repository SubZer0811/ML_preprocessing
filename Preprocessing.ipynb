{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SubZer0811/ML_preprocessing/blob/main/Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOE1fsi8srpO"
      },
      "source": [
        "# README\n",
        "\n",
        "The directory structure is as follows:\n",
        "\n",
        "\n",
        "## Description on the directory structure\n",
        "- `dataset`: This directory contains zip files each containing at most 100 images that are assigned to people for tagging. \n",
        "- `tags`: This folder contains tags in .csv format.\n",
        "- `preprocessed_data`: Since we are using yolo for object detection, the tags need to be converted to a format accepted by yolo. This directory contains zip files that contains tag files along with the images. The images in the zip folder are the same images that are present in `dataset` directory.\n",
        "- `classes.txt`: This file contains the tags present in the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKwtstBdfkb3"
      },
      "source": [
        "# Connect to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5MU-hF3fhCk"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TscXQWljU0iq"
      },
      "source": [
        "# Some path variables to make the code more readable\n",
        "\n",
        "## Description on the directory structure\n",
        "\n",
        "### DRIVE_PATH \n",
        "`DRIVE_PATH` is the path in the drive folder that contains the following files in the following structure:\n",
        "\n",
        "```\n",
        "├── classes.txt\n",
        "├── dataset\n",
        "│   └── 1.zip\n",
        "│       └── 1.jpg\n",
        "│       └── 2.jpg\n",
        "│       └── 3.jpg\n",
        "│       └── ....\n",
        "│       └── 1.txt\n",
        "│       └── 2.txt\n",
        "│       └── 3.txt\n",
        "│       └── ....\n",
        "├── preprocessed_data\n",
        "│   └── 1.zip\n",
        "└── tags\n",
        "    └── 1.csv\n",
        "```\n",
        "- `dataset`: This directory contains zip files each containing at most 100 images that are assigned to people for tagging. \n",
        "- `tags`: This folder contains tags in .csv format.\n",
        "- `preprocessed_data`: Since we are using yolo for object detection, the tags need to be converted to a format accepted by yolo. This directory contains zip files that contains tag files along with the images. The images in the zip folder are the same images that are present in `dataset` directory.\n",
        "- `classes.txt`: This file contains the tags present in the dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7LPh9e9fyGl"
      },
      "source": [
        "WORKING_DIR = \"/content/ws/\"\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/AUV\\ SOCIETY/1-CS/AUV_sim_dataset/\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqN5ZvrKg12e",
        "outputId": "6e4f1a65-3a30-41da-e607-c3734f440893"
      },
      "source": [
        "import os\n",
        "os.system(f'mkdir {WORKING_DIR}')\n",
        "os.system(f'cp -r {DRIVE_PATH}* {WORKING_DIR}')\n",
        "!ls /content/ws/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classes.txt  preprocessed_data\ttags\t\t Training_1.zip\n",
            "dataset      README.md\t\ttrained_weights\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-NzyNgQNKRA"
      },
      "source": [
        "# Load classes and colour codes for verifying\n",
        "\n",
        "The following is a code to map class id to class and vice versa. It also includes a dict to map class id to a colour."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "UB4oKK8nNIUK",
        "outputId": "4bd76d06-11ae-4670-9bb5-297996bd7143"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "classes_file = open(f'{WORKING_DIR}classes.txt')\n",
        "class_to_id = {}\n",
        "id_to_class = {}\n",
        "class_colours = {\n",
        "    0: (0, 255, 0),\n",
        "    1: (0, 0, 255),\n",
        "    2: (255, 255, 0),\n",
        "    3: (30, 110, 30),\n",
        "    4: (0, 255, 255),\n",
        "    5: (255, 0, 255),\n",
        "    6: (255, 0, 0),\n",
        "}\n",
        "\n",
        "\n",
        "l = classes_file.readline()\n",
        "count = 0\n",
        "while l:\n",
        "    class_to_id[l.strip('\\n')] = count\n",
        "    id_to_class[count] = (l.strip('\\n'), )\n",
        "    count += 1\n",
        "    l = classes_file.readline()\n",
        "\n",
        "img_3 = np.zeros([512,512,3],dtype=np.uint8)\n",
        "img_3.fill(255)\n",
        "\n",
        "x = 50; y = 50\n",
        "for id in class_colours:\n",
        "    cv2.rectangle(img_3, (x, y), (x+30, y+30), class_colours[id], -1)\n",
        "    cv2.putText(img_3, str(id_to_class[id]), (x+60, y+20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
        "\n",
        "    y += 50\n",
        "\n",
        "cv2_imshow(img_3)\n",
        "cv2.imwrite(f\"{WORKING_DIR}colour_code.png\", img_3)\n",
        "\n",
        "print(class_to_id)\n",
        "print(id_to_class)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=512x512 at 0x7F725AC327F0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'green_pole': 0, 'red_pole': 1, 'mid_pole': 2, 'gate': 3, 'obstacle': 4, 'red_bucket': 5, 'blue_bucket': 6}\n",
            "{0: ('green_pole',), 1: ('red_pole',), 2: ('mid_pole',), 3: ('gate',), 4: ('obstacle',), 5: ('red_bucket',), 6: ('blue_bucket',)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVKSjUJ7V5S1"
      },
      "source": [
        "# Assign dataset number to preprocess\n",
        "\n",
        "The folder dataset may have multiple datasets (in .zip format). Choose one of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwtM-x-xVzCq"
      },
      "source": [
        "NUMBER = 1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHmlIPUR76Xn"
      },
      "source": [
        "# Convert tags from .csv format to yolo format\n",
        "\n",
        "YOLO uses tags in a different format. The tags in .csv file are as follows:\n",
        "\n",
        "image,\txmin,\tymin,\txmax,\tymax,\tlabel\n",
        "\n",
        "YOLO requires 1 file for each image (for example if the image is 1.jpg, a file with 1.txt should hold the tags). The format required by yolo is as follows:\n",
        "\n",
        "class_id x_center_norm y_center_norm width_norm height_norm\n",
        "\n",
        "where,<br>\n",
        "`x_center` = (x-coord-center-of-boundingbox)/IMG_WIDTH <br>\n",
        "`y_center` = (y-coord-center-of-boundingbox)/IMG_HEIGHT <br>\n",
        "`width_norm` = (width-of-box)/IMG_WIDTH <br>\n",
        "`height_norm` = (height-of-box)/IMG_HEIGHT <br>\n",
        "\n",
        "The following code does the conversion and saves the tag files and images to the following directory: `WORKING_DIR/preprocessed_data/NUMBER/`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlOF4BZoidMf"
      },
      "source": [
        "%matplotlib inline\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "def convert(FILE):\n",
        "\n",
        "    yolof = open(f'{WORKING_DIR}tags/{FILE}', 'r')\n",
        "    print(f\"{WORKING_DIR}tags/{FILE}\")\n",
        "    preprocessed_data = f'{WORKING_DIR}preprocessed_data/{NUMBER}/'\n",
        "    os.system(f'mkdir {preprocessed_data}')\n",
        "    testing_set = f'{WORKING_DIR}testing_set/{NUMBER}/'\n",
        "    os.system(f'mkdir {testing_set}')\n",
        "\n",
        "    dataset = f'{WORKING_DIR}dataset/'\n",
        "    os.system(f'unzip -j {dataset}{NUMBER}.zip -d {dataset}{NUMBER}')\n",
        "    dataset = dataset + str(NUMBER) + '/'\n",
        "\n",
        "    j = 1\n",
        "    TEST_TOTAL = 5\n",
        "    test_count = 0\n",
        "\n",
        "    line = yolof.readline()\n",
        "    line = yolof.readline()\n",
        "\n",
        "    while (line != ''):\n",
        "\n",
        "        spl = line.strip('\\n').split(sep=',')\n",
        "        \n",
        "        img_name = spl[0].strip('\"')\n",
        "        img_path = dataset + img_name\n",
        "        print(img_path)\n",
        "        img = cv2.imread(img_path)\n",
        "        \n",
        "        # if random.randrange(1000)%99 == 0 and test_count < TEST_TOTAL:\n",
        "        #     filename = testing_set + img_name.split(sep='.')[0] + \".txt\"\n",
        "        #     os.system(f'cp {img_path} {testing_set}')\n",
        "\n",
        "        # else:\n",
        "        #     filename = training_set + img_name.split(sep='.')[0] + \".txt\"\n",
        "        #     os.system(f'cp {img_path} {training_set}')\n",
        "\n",
        "        filename = preprocessed_data + img_name.split(sep='.')[0] + \".txt\"\n",
        "        os.system(f'cp {img_path} {preprocessed_data}')\n",
        "\n",
        "        txtfile = open(filename, 'a')\n",
        "\n",
        "        text = spl[1:-1]\n",
        "        text = [float(i) for i in text]\n",
        "\n",
        "        x = (text[0] + text[2])/2           # center of box\n",
        "        y = (text[1] + text[3])/2           # center of box\n",
        "        w = text[2] - text[0]               # width of box\n",
        "        h = text[3] - text[1]               # height of box\n",
        "\n",
        "        class_ = spl[-1].strip('\"\\n')\n",
        "\n",
        "        dncoords = ''\n",
        "        dncoords += str(class_to_id[class_]) + ' '\n",
        "        dncoords += str(x/img.shape[1]) + ' '\n",
        "        dncoords += str(y/img.shape[0]) + ' '\n",
        "        dncoords += str(w/img.shape[1]) + ' '\n",
        "        dncoords += str(h/img.shape[0]) + '\\n'\n",
        "\n",
        "        txtfile.writelines(dncoords)\n",
        "\n",
        "        line = yolof.readline()\n",
        "        j+=1\n",
        "\n",
        "convert(f\"{NUMBER}.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik1wAe22TcVV"
      },
      "source": [
        "# Check if all images are annotated correctly\n",
        "\n",
        "The following code can be used to check whether the images are tagged properly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE0wYamkTTSf"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output \n",
        "\n",
        "def show(img_path):\n",
        "\n",
        "    print(img_path)\n",
        "    img = cv2.imread(img_path)\n",
        "    f = open(img_path.split('.')[0] + \".txt\")\n",
        "    dh, dw, _ = img.shape\n",
        "\n",
        "    line = f.readline()\n",
        "\n",
        "    while line:\n",
        "\n",
        "        class_id, x, y, w, h = map(float, line.split(' '))\n",
        "        \n",
        "        l = int((x - w / 2) * dw)\n",
        "        r = int((x + w / 2) * dw)\n",
        "        t = int((y - h / 2) * dh)\n",
        "        b = int((y + h / 2) * dh)\n",
        "        \n",
        "        if l < 0:\n",
        "            l = 0\n",
        "        if r > dw - 1:\n",
        "            r = dw - 1\n",
        "        if t < 0:\n",
        "            t = 0\n",
        "        if b > dh - 1:\n",
        "            b = dh - 1\n",
        "\n",
        "        cv2.rectangle(img, (l, t), (r, b), class_colours[class_id], 2)\n",
        "        cv2.putText(img, img_path.split('/')[-1], (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "        \n",
        "        line = f.readline()\n",
        "    f.close()\n",
        "\n",
        "    cv2_imshow(img)\n",
        "    cv2.waitKey()\n",
        "\n",
        "# imgs = os.listdir(f'{WORKING_DIR}testing_set/{NUMBER}')\n",
        "\n",
        "# for x in imgs:\n",
        "#     if x.endswith('.jpg'):\n",
        "#         show(f'{WORKING_DIR}testing_set/{NUMBER}/{x}')\n",
        "#         # cv2.waitKey()\n",
        "#         # clear_output()\n",
        "\n",
        "\n",
        "imgs = os.listdir(f'{WORKING_DIR}preprocessed_data/{NUMBER}')\n",
        "\n",
        "for x in imgs:\n",
        "    if x.endswith('.jpg'):\n",
        "        show(f'{WORKING_DIR}preprocessed_data/{NUMBER}/{x}')\n",
        "        # clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeoBUYBZVVjB"
      },
      "source": [
        "# Save converted tags along with images to cloud\n",
        "\n",
        "This following code zips the dataset `NUMBER` (which contains both yolo tag files and images) and saves it in `DRIVE_PATH/preprocessed_data/` as a .zip file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoVW4wmtOhQj"
      },
      "source": [
        "os.system(f'cd {WORKING_DIR}preprocessed_data/; zip -r -D {DRIVE_PATH}/preprocessed_data/{NUMBER}.zip {NUMBER}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD68MTuXIc2v"
      },
      "source": [
        "# Generate file structure for training with darknet\n",
        "\n",
        "Once enough images have been tagged and converted, the following blocks can be run. \n",
        "\n",
        "So till now, you must have multiple .zip files each containing tags and images in preprocessed_data folder.\n",
        "\n",
        "You must have the following files/directories for training using darknet:\n",
        "\n",
        "Training_[ ] contains the following directory structure: \n",
        "\n",
        "```\n",
        ".\n",
        "├── cfg\n",
        "├── classes.txt\n",
        "├── detector.data\n",
        "├── images\n",
        "│       └── 1.jpg\n",
        "│       └── 1.txt\n",
        "│       └── 2.jpg\n",
        "│       └── 2.txt\n",
        "│       └── 3.jpg\n",
        "│       └── 3.txt\n",
        "│       └── ....\n",
        "├── test.txt\n",
        "├── train.txt\n",
        "├── valid.txt\n",
        "└── weights\n",
        "\n",
        "```\n",
        "- `images`: This folder contains all images along with tag files for each image.\n",
        "- `cfg`: This folder should contain the configuration file for training on darknet. This folder might not contain any configuration file in which case, you may need to create one.\n",
        "- `weights`: This folder contains the weights that may have been obtained from training.\n",
        "- `train.txt`: This file contains the path to images in training set.\n",
        "- `test.txt`: This file contains the path to images in testing set.\n",
        "- `valid.txt`: This file contains the path to images in validation set.\n",
        "- `classes.txt`: This file contains the tags present in the dataset.\n",
        "- `detector.data`: This file contains the path to the above mentioned directories and files for darknet.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gt2_z5qSnFr"
      },
      "source": [
        "The following will be the name of the folder containing the abovev mentioned files and folders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmG-avDqIcgp"
      },
      "source": [
        "FOLDER_NAME = \"Training_1/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5toLyld7I71a"
      },
      "source": [
        "os.system(f\"mkdir -p {WORKING_DIR}{FOLDER_NAME}weights\")\n",
        "os.system(f\"mkdir -p {WORKING_DIR}{FOLDER_NAME}images\")\n",
        "os.system(f\"mkdir -p {WORKING_DIR}{FOLDER_NAME}cfg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aLS1ZkbSvyb"
      },
      "source": [
        "`to_be_unzipped`: This list contains the names of .zip files that contain images and tags that needs to be used for training.\n",
        "\n",
        "Here we have used a 80:10:10 ratio for the training:validation:testing sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEKZu1sLWO4Q"
      },
      "source": [
        "import random\n",
        "\n",
        "to_be_unzipped = [1, 2, 3, 4, 5, 6, 7]\n",
        "\n",
        "os.system(f\"mkdir -p {WORKING_DIR}{FOLDER_NAME}tmp\")\n",
        "\n",
        "for id in to_be_unzipped:\n",
        "    os.system(f'unzip -j {WORKING_DIR}preprocessed_data/{id}.zip -d {WORKING_DIR}Training_1/images')\n",
        "\n",
        "list_dir = os.listdir(f'{WORKING_DIR}Training_1/images')\n",
        "imgs = []\n",
        "org_imgs = []\n",
        "train = []\n",
        "valid = []\n",
        "test = []\n",
        "\n",
        "for x in list_dir:\n",
        "    if x.endswith('.jpg'):\n",
        "        imgs.append(x)\n",
        "\n",
        "org_imgs = imgs.copy()\n",
        "len_train = int(0.8 * len(imgs))\n",
        "len_valid = int(0.1 * len(imgs))\n",
        "len_test = len(imgs) - len_train - len_valid\n",
        "\n",
        "print(f\"TOTAL: {len(imgs)}\")\n",
        "print(f'len_train: {len_train}')\n",
        "print(f'len_valid: {len_valid}')\n",
        "print(f'len_test: {len_test}')\n",
        "\n",
        "for i in range(len_train):\n",
        "    id = random.randint(0, len(imgs)-1)\n",
        "    train.append(imgs[id])\n",
        "    imgs.remove(imgs[id])\n",
        "\n",
        "for i in range(len_test):\n",
        "    id = random.randint(0, len(imgs)-1)\n",
        "    test.append(imgs[id])\n",
        "    imgs.remove(imgs[id])\n",
        "\n",
        "valid = imgs\n",
        "\n",
        "print(f'\\nlen_train: {len(train)}')\n",
        "print(f'len_valid: {len(valid)}')\n",
        "print(f'len_test: {len(test)}')\n",
        "\n",
        "# VERIFY IF SETS ARE MUTUALLY EXCLUSIVE\n",
        "temp = test + train + valid\n",
        "temp.sort()\n",
        "org_imgs.sort()\n",
        "print(temp)\n",
        "print(org_imgs)\n",
        "\n",
        "if org_imgs == temp:\n",
        "    print(\"MUTUALLY EXCLUSIVE\")\n",
        "\n",
        "    train_file = open(f'{WORKING_DIR}{FOLDER_NAME}train.txt', 'w')\n",
        "    for i in train:\n",
        "        train_file.write(f'images/{i}\\n')\n",
        "    train_file.close()\n",
        "\n",
        "    test_file = open(f'{WORKING_DIR}{FOLDER_NAME}test.txt', 'w')\n",
        "    for i in test:\n",
        "        test_file.write(f'images/{i}\\n')\n",
        "    test_file.close()\n",
        "\n",
        "    valid_file = open(f'{WORKING_DIR}{FOLDER_NAME}valid.txt', 'w')\n",
        "    for i in valid:\n",
        "        valid_file.write(f'images/{i}\\n')\n",
        "    valid_file.close()\n",
        "\n",
        "else:\n",
        "    print(\"ERROR\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xHDXrr2VjHA"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DliBRJPllmo8"
      },
      "source": [
        "os.system(f\"cp {WORKING_DIR}classes.txt {WORKING_DIR}{FOLDER_NAME}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNWFzU5dVo6X"
      },
      "source": [
        "FINALLY This command zips the training directory and saves it on google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11wVWliBmqvx"
      },
      "source": [
        "os.system(f'cd {WORKING_DIR}; zip -r {DRIVE_PATH}{FOLDER_NAME[:-1]}.zip {FOLDER_NAME}*')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUA8gTpgVQgy"
      },
      "source": [
        "# REVERT\n",
        "\n",
        "THIS CAN BE USED TO RESET THE WORKING DIRECTORY. DO NOT COPY ANYTHING TO DRIVE WITHOUT VERIFYING.\n",
        "\n",
        "IF AT ALL SOMETHING SCREWED UP IN THE COLAB WORKING_DIR, YOU CAN ALWAYS RUN THE FOLLOWING BLOCK TO RESET. \n",
        "\n",
        "ONCE RESET, GO BACK TO THE CELL THAT DEFINES THE PATHS AND RUN FORM THERE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAN-aT9YAWLQ"
      },
      "source": [
        "os.system(f'rm -r {WORKING_DIR}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}